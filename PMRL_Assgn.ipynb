{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PMRL_Assgn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fakirmohan5/Data-Contest-on-kaggle/blob/main/PMRL_Assgn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0OHNpTVVE7Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5dqvclVOSC"
      },
      "source": [
        "df=pd.read_csv(r\"C:\\Users\\Fakir\\Code\\PRML ASSIGNMENT\\assgn2\\Dataset_1_Training.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz_70Q2mVOom"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlsqSWHJVOz1"
      },
      "source": [
        "df=df.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L3kiVFYVO-0"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAjyLuJwVPId"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82i1PcL2VPLf"
      },
      "source": [
        "new_header = df.iloc[0] #grab the first row for the header\n",
        "df = df[1:] #take the data less the header row\n",
        "df.columns = new_header"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJBJgzUIVPOK"
      },
      "source": [
        "df_y1=df['CO: 1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBXdhqOsVPQ1"
      },
      "source": [
        "df_y2=df['CO: 2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkCaOLuLVPTQ"
      },
      "source": [
        "df_y2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_HAGojVPYv"
      },
      "source": [
        "df_y1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8xIZVVdVPbo"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XSx23PHVPeE"
      },
      "source": [
        "df.drop(['CO: 1', 'CO: 2'], axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAAiSUkxV2eQ"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF_TFl99V2oc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDaCcIOV5UJ"
      },
      "source": [
        "lr=LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUNfhTJMVPi-"
      },
      "source": [
        "lr.fit(df,df_y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBvoqSgfXVky"
      },
      "source": [
        "predict=lr.predict(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvdeGpnXVqR"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXcbK4gqXVxj"
      },
      "source": [
        "pd.Dataframe(confusion_matrix(df_y1,predict),columns=[\"predicted No\",'Predicted yes'],index=[\"actal No\", \"actual yes\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5h0BGsHXV0t"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5zxbCXxZLRN"
      },
      "source": [
        "print(classification_report(df_y1,predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CosTMNhYvr9w"
      },
      "source": [
        "#Logistic regression for all clinical descriptors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1 = pd.read_csv(\"Dataset_1_Training.csv\",header=None, dtype='unicode')\n",
        "df2 = pd.read_csv(\"Dataset_1_Testing.csv\",header=None,  dtype='unicode')\n",
        "df3 = pd.read_csv(\"Dataset_2_Training.csv\",header=None, dtype='unicode')\n",
        "df4 = pd.read_csv(\"Dataset_2_Testing.csv\",header=None, dtype='unicode')\n",
        "\n",
        "X1 = df1.iloc[1:-2,1:] #independent columns\n",
        "X1= X1.T\n",
        "#print(X1)\n",
        "yCo1 = df1.iloc[-2,1:]\n",
        "yCo1=yCo1.astype('int')\n",
        "yCo2 = df1.iloc[-1,1:]\n",
        "yCo2=yCo2.astype('int')\n",
        "#print(yCo2)\n",
        "\n",
        "X2 = df3.iloc[1:-4,1:] #independent columns\n",
        "X2= X2.T\n",
        "print(X2)\n",
        "yCo3 = df3.iloc[-4,1:]\n",
        "yCo3=yCo3.astype('int')\n",
        "yCo4 = df3.iloc[-3,1:]\n",
        "yCo4=yCo4.astype('int')\n",
        "yCo5 = df3.iloc[-2,1:]\n",
        "yCo5=yCo5.astype('int')\n",
        "yCo6 = df3.iloc[-1,1:]\n",
        "yCo6=yCo6.astype('int')\n",
        "#print(yCo2)\n",
        "\n",
        "X1_test= df2.iloc[1:,1:]\n",
        "X1_test= X1_test.T\n",
        "#print(X1_test)\n",
        "\n",
        "X2_test= df4.iloc[1:,1:]\n",
        "X2_test= X2_test.T\n",
        "#print(X2_test)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardizer = StandardScaler()\n",
        "X1 = standardizer.fit_transform(X1)\n",
        "X1_test = standardizer.fit_transform(X1_test)\n",
        "\n",
        "X2 = standardizer.fit_transform(X2)\n",
        "X2_test = standardizer.fit_transform(X2_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X1, yCo1)\n",
        "predictionsCo1 = model.predict(X1_test)\n",
        "model.fit(X1, yCo2)\n",
        "predictionsCo2 = model.predict(X1_test)\n",
        "\n",
        "model.fit(X2, yCo3)\n",
        "predictionsCo3 = model.predict(X2_test)\n",
        "model.fit(X2, yCo4)\n",
        "predictionsCo4 = model.predict(X2_test)\n",
        "model.fit(X2, yCo5)\n",
        "predictionsCo5 = model.predict(X2_test)\n",
        "model.fit(X2, yCo6)\n",
        "predictionsCo6 = model.predict(X2_test)\n",
        "\n",
        "print(predictionsCo1)\n",
        "print(predictionsCo2)\n",
        "predictions = np.concatenate((predictionsCo1, predictionsCo2,predictionsCo3,predictionsCo4,predictionsCo5,predictionsCo6))\n",
        "print(predictions)\n",
        "dCo1= pd.DataFrame(predictions)\n",
        "dCo1.to_csv('file_name17.csv',header=[\"Predicted\"],index_label='Id')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEnE2_VDrhQX"
      },
      "source": [
        "### for SVM ####\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "classifier=svm.SVC(kernel='linear',gamma='auto',C=2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Kf1nfDFWYL"
      },
      "source": [
        "### for RandomForest ####\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier=RandomForestClassifier()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMH15y9pkyyi"
      },
      "source": [
        "The bagging arguments used for \n",
        "\n",
        "#####\n",
        "\n",
        "classifier=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=15)\n",
        "\n",
        "\n",
        "####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4KgjMef_L6W"
      },
      "source": [
        "### bagging 1 ####\n",
        "classifier=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=20)\n",
        "\n",
        "#####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0hCf9Ho_MNl"
      },
      "source": [
        "#### bagging 2 ####\n",
        "classifier=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=18)\n",
        "\n",
        "#####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by5o0omB_iXr"
      },
      "source": [
        "#### bagging 4 ####\n",
        "classifier=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.1,max_features=1.0,n_estimators=15)\n",
        "\n",
        "\n",
        "####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqmggK9i50va"
      },
      "source": [
        "### for Ada boost ####\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "classifier=AdaBoostClassifier(DecisionTreeClassifier(),n_estimators=5,learning_rate=1)\n",
        "\n",
        "###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Craw8jKOU3"
      },
      "source": [
        "#adaboost with svm classifier\n",
        "classifiers=svm.SVC(kernel='poly',gamma='auto',C=2)\n",
        "classifier = AdaBoostClassifier(base_estimator=classifiers,algorithm='SAMME')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rekNP0j0KV6H"
      },
      "source": [
        "#adaboost with Logistic regression classifier\n",
        "classifiers=LogisticRegression()\n",
        "classifier = AdaBoostClassifier(base_estimator=classifiers,algorithm='SAMME')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IusRcxb597X"
      },
      "source": [
        "#Best score code 0.49144\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "df1 = pd.read_csv(\"Dataset_1_Training.csv\",header=None, dtype='unicode')\n",
        "df2 = pd.read_csv(\"Dataset_1_Testing.csv\",header=None,  dtype='unicode')\n",
        "df3 = pd.read_csv(\"Dataset_2_Training.csv\",header=None, dtype='unicode')\n",
        "df4 = pd.read_csv(\"Dataset_2_Testing.csv\",header=None, dtype='unicode')\n",
        "\n",
        "X1=df1.iloc[1:-2,1:]\n",
        "X1=X1.T\n",
        "X1 = StandardScaler().fit_transform(X1)\n",
        "#print(X1)\n",
        "\n",
        "X2=df3.iloc[1:-4,1:]\n",
        "X2=X2.T\n",
        "X2 = StandardScaler().fit_transform(X2)\n",
        "#print(X2)\n",
        "\n",
        "yCo1 = df1.iloc[-2,1:]\n",
        "yCo1=yCo1.astype('int')\n",
        "yCo2 = df1.iloc[-1,1:]\n",
        "yCo2=yCo2.astype('int')\n",
        "#print(yCo2)\n",
        "\n",
        "\n",
        "yCo3 = df3.iloc[-4,1:]\n",
        "yCo3=yCo3.astype('int')\n",
        "yCo4 = df3.iloc[-3,1:]\n",
        "yCo4=yCo4.astype('int')\n",
        "yCo5 = df3.iloc[-2,1:]\n",
        "yCo5=yCo5.astype('int')\n",
        "yCo6 = df3.iloc[-1,1:]\n",
        "yCo6=yCo6.astype('int')\n",
        "#print(yCo2)\n",
        "\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(\"Dataset_1_Training.csv\",header=None, dtype='unicode')\n",
        "df2 = pd.read_csv(\"Dataset_1_Testing.csv\",header=None,  dtype='unicode')\n",
        "df3 = pd.read_csv(\"Dataset_2_Training.csv\",header=None, dtype='unicode')\n",
        "df4 = pd.read_csv(\"Dataset_2_Testing.csv\",header=None, dtype='unicode')\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "# k=5\n",
        "# K-Fold crossvalidation test on the models for all given dataset and descriptor combination and the output results are given as table in written document\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.average(cross_val_score(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100),X2,yCo6))\n",
        "\n",
        "\n",
        "\n",
        "np.average(cross_val_score(AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME'),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME'),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME'),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME'),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME'),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME'),X2,yCo6))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.average(cross_val_score(LogisticRegression(),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(SVC(),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=40),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=60),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(GradientBoostingClassifier(),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(GaussianNB(),X1,yCo1))\n",
        "\n",
        "np.average(cross_val_score(GaussianNB(),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(LogisticRegression(),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(SVC(),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=40),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=60),X1,yCo2))\n",
        "\n",
        "np.average(cross_val_score(GradientBoostingClassifier(),X1,yCo2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.average(cross_val_score(GaussianNB(),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(LogisticRegression(),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(SVC(),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=40),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=60),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=100),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(GradientBoostingClassifier(),X2,yCo3))\n",
        "\n",
        "np.average(cross_val_score(GaussianNB(),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(GaussianNB(),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(GaussianNB(),X2,yCo6))\n",
        "\n",
        "np.average(cross_val_score(LogisticRegression(),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(LogisticRegression(),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(LogisticRegression(),X2,yCo6))\n",
        "\n",
        "np.average(cross_val_score(SVC(kernel='linear',gamma='auto',C=2),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(SVC(),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(SVC(),X2,yCo6))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=40),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=60),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=100),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=70),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=40),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=60),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=40),X2,yCo6))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=10),X2,yCo6))\n",
        "\n",
        "np.average(cross_val_score(RandomForestClassifier(n_estimators=60),X2,yCo6))\n",
        "\n",
        "np.average(cross_val_score(GradientBoostingClassifier(),X2,yCo4))\n",
        "\n",
        "np.average(cross_val_score(GradientBoostingClassifier(),X2,yCo5))\n",
        "\n",
        "np.average(cross_val_score(GradientBoostingClassifier(),X2,yCo6))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x11_train,x11_test,y11_train,y11_test=train_test_split(X1,yCo1,test_size=0.3,random_state=10)  #values will no shuffle for random_state 10\n",
        "x12_train,x12_test,y12_train,y12_test=train_test_split(X1,yCo2,test_size=0.3,random_state=10)\n",
        "x23_train,x23_test,y23_train,y23_test=train_test_split(X2,yCo3,test_size=0.3,random_state=10)\n",
        "x24_train,x24_test,y24_train,y24_test=train_test_split(X2,yCo4,test_size=0.3,random_state=10)\n",
        "x25_train,x25_test,y25_train,y25_test=train_test_split(X2,yCo5,test_size=0.3,random_state=10)\n",
        "x26_train,x26_test,y26_train,y26_test=train_test_split(X2,yCo6,test_size=0.3,random_state=10)\n",
        "\n",
        "\n",
        "#for accuracy score for all the used models using class-balanced datasets and the results are noted in the written report in tabular fashion\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=60)\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "classifier = SVC(kernel='rbf',gamma='auto',C=2)\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "classifier = AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "classifier = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100)\n",
        "classifier.fit(x11_train,y11_train)\n",
        "y11_predict=classifier.predict(x11_test)\n",
        "print(\"accuracy score\",accuracy_score(y11_test,y11_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=60)\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "classifier = SVC(kernel='rbf',gamma='auto',C=2)\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "classifier = AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "classifier = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100)\n",
        "classifier.fit(x12_train,y12_train)\n",
        "y12_predict=classifier.predict(x12_test)\n",
        "print(\"accuracy score\",accuracy_score(y12_test,y12_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=60)\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "classifier = SVC(kernel='rbf',gamma='auto',C=2)\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "classifier = AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "classifier =  LogisticRegression()\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "classifier =  BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100)\n",
        "classifier.fit(x23_train,y23_train)\n",
        "y23_predict=classifier.predict(x23_test)\n",
        "print(\"accuracy score\",accuracy_score(y23_test,y23_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=60)\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "classifier = SVC(kernel='rbf',gamma='auto',C=2)\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "classifier = AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "classifier = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100)\n",
        "classifier.fit(x25_train,y25_train)\n",
        "y25_predict=classifier.predict(x25_test)\n",
        "print(\"accuracy score\",accuracy_score(y25_test,y25_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=60)\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "classifier = SVC(kernel='rbf',gamma='auto',C=2)\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "classifier = AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "classifier = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100)\n",
        "classifier.fit(x26_train,y26_train)\n",
        "y26_predict=classifier.predict(x26_test)\n",
        "print(\"accuracy score\",accuracy_score(y26_test,y26_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for F1 score of 4th descriptor\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "classifier =  RandomForestClassifier(n_estimators=60)\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "classifier = SVC(kernel='rbf',gamma='auto',C=2)\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "classifier = AdaBoostClassifier(base_estimator=SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "classifier =  BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=100)\n",
        "classifier.fit(x24_train,y24_train)\n",
        "y24_predict=classifier.predict(x24_test)\n",
        "print(classification_report(y24_test,y24_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for feature extraction but chi-square will not work here as some values are negative\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "\n",
        "bestfeatures=SelectKBest(score_func=chi2,k=100)\n",
        "fit=bestfeatures.fit(X1,yCo1)\n",
        "\n",
        "dfscores=pd.DataFrame(fit.scores_)\n",
        "dfcolumns=pd.DataFrame(X1.columns)\n",
        "\n",
        "featureScores=pd.contact([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns=['Specs','Score']\n",
        "\n",
        "featureScores\n",
        "\n",
        "\n",
        "\n",
        "# for feature importance\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "model= ExtraTreesClassifier()\n",
        "model.fit(X1,yCo1)\n",
        "\n",
        "print(model.feature_importances_)\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "plt.rcParams['figure.figsize']=(10,12)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "feat_importances=pd.Series(model.feature_importances_,index=X1.columns)\n",
        "feat_importances.nlargest(50).plot(kind='barh')\n",
        "plt.show()\n",
        "\n",
        "model.fit(X1,yCo2)\n",
        "feat_importances=pd.Series(model.feature_importances_,index=X1.columns)\n",
        "feat_importances.nlargest(50).plot(kind='barh')\n",
        "plt.show()\n",
        "\n",
        "model.fit(X2,yCo3)\n",
        "feat_importances=pd.Series(model.feature_importances_,index=X2.columns)\n",
        "feat_importances.nlargest(50).plot(kind='barh')\n",
        "plt.show()\n",
        "\n",
        "model.fit(X2,yCo4)\n",
        "feat_importances=pd.Series(model.feature_importances_,index=X2.columns)\n",
        "feat_importances.nlargest(50).plot(kind='barh')\n",
        "plt.show()\n",
        "\n",
        "model.fit(X2,yCo5)\n",
        "feat_importances=pd.Series(model.feature_importances_,index=X2.columns)\n",
        "feat_importances.nlargest(50).plot(kind='barh')\n",
        "plt.show()\n",
        "\n",
        "model.fit(X2,yCo6)\n",
        "feat_importances=pd.Series(model.feature_importances_,index=X2.columns)\n",
        "feat_importances.nlargest(50).plot(kind='barh')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "pip install Ipython\n",
        "\n",
        "import eli5\n",
        "from eli5 import formatters\n",
        "#from Ipython.display import display\n",
        "#display(eli5.explain_weights(classifier,feature_names=list(features),importance_type='gain'))\n",
        "#eli5.explain_weights(classifier,feature_names=list(features),importance_type='gain')\n",
        "eli5.explain_weights(classifier,top=50)\n",
        "\n",
        "pip install eli5\n",
        "\n",
        "from eli5 import show_weights\n",
        "\n",
        "show_weights(classifier, feature_names=X1.feature_names)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "X1_test= df2.iloc[1:,1:]\n",
        "X1_test= X1_test.T\n",
        "X1_test = StandardScaler().fit_transform(X1_test)\n",
        "#print(X1_test)\n",
        "\n",
        "X2_test= df4.iloc[1:,1:]\n",
        "X2_test= X2_test.T\n",
        "#print(X2_test)\n",
        "X2_test = StandardScaler().fit_transform(X2_test)\n",
        "#print(X2_test)\n",
        "\n",
        "\n",
        "model1 = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=800)\n",
        "model1.fit(X1, yCo1)\n",
        "predictionsCo1 = model1.predict(X1_test)\n",
        "\n",
        "model2 = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=1200)\n",
        "model2.fit(X1, yCo2)\n",
        "predictionsCo2 = model2.predict(X1_test)\n",
        "\n",
        "model3 = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=400)\n",
        "model3.fit(X2, yCo3)\n",
        "predictionsCo3 = model3.predict(X2_test)\n",
        "\n",
        "model4 =BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=1600)\n",
        "model4.fit(X2, yCo4)\n",
        "predictionsCo4 = model4.predict(X2_test)\n",
        "\n",
        "model5 = BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=800)\n",
        "model5.fit(X2, yCo5)\n",
        "predictionsCo5 = model5.predict(X2_test)\n",
        "\n",
        "model6 = AdaBoostClassifier(base_estimator=svm.SVC(kernel='rbf',gamma='auto',C=2), algorithm='SAMME')\n",
        "model6.fit(X2, yCo6)\n",
        "predictionsCo6 = model6.predict(X2_test)\n",
        "\n",
        "#print(predictionsCo1)\n",
        "#print(predictionsCo2)\n",
        "predictions = np.concatenate((predictionsCo1, predictionsCo2,predictionsCo3,predictionsCo4,predictionsCo5,predictionsCo6))\n",
        "#print(predictions)\n",
        "dCo1= pd.DataFrame(predictions)\n",
        "dCo1.to_csv('49Best.csv',header=[\"Predicted\"],index_label='Id')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}